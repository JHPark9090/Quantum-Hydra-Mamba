Starting job: syn_2d_adding_problem_L100_s2026
Date: Wed 07 Jan 2026 10:31:53 AM PST
Host: nid008697
GPU: NVIDIA A100-SXM4-80GB
Using GPU: NVIDIA A100-SXM4-80GB
================================================================================
SYNTHETIC BENCHMARK - ADDING_PROBLEM
================================================================================
Model ID: 2d (QuantumMambaHydraSSM)
  Group 2: classical feat → quantum_superposition mix (mamba)
Task: adding_problem (regression)
Sequence Length: 100
Seed: 2026
Device: cuda
--------------------------------------------------------------------------------
Hyperparameters:
  n_qubits=6, n_layers=2
  d_model=128, d_state=16
  epochs=100, batch_size=32
  lr=0.001, weight_decay=0.0001
  early_stopping=20
================================================================================

Loading Data...
Loading Adding Problem dataset from data/synthetic_benchmarks/adding_problem/adding_L100_seed2026.pt...
Dataset loaded successfully.
  - Task: adding_problem
  - Sequence length: 100
  - Num channels: 2
  - Total samples: 5000
  - Marker strategy: extremes
  - Baseline MSE: 0.1660
  - Shape for model: torch.Size([5000, 2, 100])
  - Training set: 4000
  - Validation set: 500
  - Test set: 500
Data loaded!
  Input: (2 channels, 100 timesteps)
  Output dim: 1

Creating model...
Creating model: QuantumMambaHydraSSM (ID: 2d)
  Group 2: classical features → quantum_superposition mixing (mamba)
Model parameters: 46,052
Verifying device placement...
  WARNING: input_proj.0.weight is on cuda:0, moving to cuda
  WARNING: input_proj.0.bias is on cuda:0, moving to cuda
  WARNING: input_proj.1.weight is on cuda:0, moving to cuda
  WARNING: input_proj.1.bias is on cuda:0, moving to cuda
  WARNING: chunk_attention.0.weight is on cuda:0, moving to cuda
  WARNING: chunk_attention.0.bias is on cuda:0, moving to cuda
  WARNING: chunk_attention.2.weight is on cuda:0, moving to cuda
  WARNING: chunk_attention.2.bias is on cuda:0, moving to cuda
  WARNING: forward_param_proj.weight is on cuda:0, moving to cuda
  WARNING: forward_param_proj.bias is on cuda:0, moving to cuda
  WARNING: backward_param_proj.weight is on cuda:0, moving to cuda
  WARNING: backward_param_proj.bias is on cuda:0, moving to cuda
  WARNING: diagonal_param_proj.weight is on cuda:0, moving to cuda
  WARNING: diagonal_param_proj.bias is on cuda:0, moving to cuda
  WARNING: encoding_proj.weight is on cuda:0, moving to cuda
  WARNING: encoding_proj.bias is on cuda:0, moving to cuda
  WARNING: dt_proj.0.weight is on cuda:0, moving to cuda
  WARNING: dt_proj.0.bias is on cuda:0, moving to cuda
  WARNING: dt_proj.2.weight is on cuda:0, moving to cuda
  WARNING: dt_proj.2.bias is on cuda:0, moving to cuda
  WARNING: quantum_core.alpha_real is on cuda:0, moving to cuda
  WARNING: quantum_core.alpha_imag is on cuda:0, moving to cuda
  WARNING: quantum_core.beta_real is on cuda:0, moving to cuda
  WARNING: quantum_core.beta_imag is on cuda:0, moving to cuda
  WARNING: quantum_core.gamma_real is on cuda:0, moving to cuda
  WARNING: quantum_core.gamma_imag is on cuda:0, moving to cuda
  WARNING: output_proj.0.weight is on cuda:0, moving to cuda
  WARNING: output_proj.0.bias is on cuda:0, moving to cuda
  WARNING: output_proj.1.weight is on cuda:0, moving to cuda
  WARNING: output_proj.1.bias is on cuda:0, moving to cuda
  WARNING: seq_attention.0.weight is on cuda:0, moving to cuda
  WARNING: seq_attention.0.bias is on cuda:0, moving to cuda
  WARNING: seq_attention.2.weight is on cuda:0, moving to cuda
  WARNING: seq_attention.2.bias is on cuda:0, moving to cuda
  WARNING: classifier.0.weight is on cuda:0, moving to cuda
  WARNING: classifier.0.bias is on cuda:0, moving to cuda
  WARNING: classifier.3.weight is on cuda:0, moving to cuda
  WARNING: classifier.3.bias is on cuda:0, moving to cuda
Model moved to cuda

================================================================================
Training Started (epochs 1 to 100)
================================================================================

Epoch   1/100 (374.5s) * | Train MSE: 0.141212 | Val MSE: 0.002172
Epoch   2/100 (372.7s) * | Train MSE: 0.009296 | Val MSE: 0.001646
Epoch   3/100 (375.6s) * | Train MSE: 0.006794 | Val MSE: 0.000628
Epoch   4/100 (375.9s) * | Train MSE: 0.005899 | Val MSE: 0.000527
Epoch   5/100 (375.2s) | Train MSE: 0.005031 | Val MSE: 0.002609
Epoch   8/100 (372.4s) * | Train MSE: 0.003816 | Val MSE: 0.000474
Epoch  10/100 (370.5s) | Train MSE: 0.003545 | Val MSE: 0.001823
Epoch  13/100 (370.0s) * | Train MSE: 0.003387 | Val MSE: 0.000232
Epoch  15/100 (370.3s) * | Train MSE: 0.003461 | Val MSE: 0.000050
Epoch  20/100 (370.4s) * | Train MSE: 0.002862 | Val MSE: 0.000037
Epoch  25/100 (367.7s) | Train MSE: 0.002718 | Val MSE: 0.000285
Epoch  30/100 (367.2s) | Train MSE: 0.002199 | Val MSE: 0.000305
Epoch  35/100 (362.5s) | Train MSE: 0.002166 | Val MSE: 0.000064
Epoch  40/100 (362.4s) | Train MSE: 0.001894 | Val MSE: 0.000148

Early stopping at epoch 40 (no improvement for 20 epochs)

================================================================================
Training Complete!
================================================================================
Total Time: 14757.80s (245.96 min)
Best Val MSE: 0.000037
Test Results:
  MSE: 0.000041
  MAE: 0.004890
  R²: 0.9998
  Baseline MSE: 0.1670
  Improvement over baseline: 100.0%

Results saved to: results/synthetic_benchmarks/synthetic_2d_adding_problem_L100_seed2026_results.json
Model saved to: results/synthetic_benchmarks/synthetic_2d_adding_problem_L100_seed2026_model.pt
Cleaned up training checkpoint: results/synthetic_benchmarks/checkpoints/checkpoint_2d_adding_problem_L100_seed2026.pt

================================================================================
SYNTHETIC BENCHMARK RUN COMPLETE
================================================================================
Model: 2d (QuantumMambaHydraSSM)
Task: adding_problem
Seq Length: 100
Test MSE: 0.000041
Test R²: 0.9998
================================================================================

Job completed: syn_2d_adding_problem_L100_s2026
End time: Wed 07 Jan 2026 02:38:31 PM PST
