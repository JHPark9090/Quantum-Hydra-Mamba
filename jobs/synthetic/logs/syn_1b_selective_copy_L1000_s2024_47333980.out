Starting job: syn_1b_selective_copy_L1000_s2024
Date: Sun 04 Jan 2026 02:14:16 PM PST
Host: nid008545
GPU: NVIDIA A100-SXM4-80GB
Using GPU: NVIDIA A100-SXM4-80GB
================================================================================
SYNTHETIC BENCHMARK - SELECTIVE_COPY
================================================================================
Model ID: 1b (QuantumMambaSSM)
  Group 1: quantum feat → classical mix (mamba)
Task: selective_copy (regression)
Sequence Length: 1000
Seed: 2024
Device: cuda
--------------------------------------------------------------------------------
Hyperparameters:
  n_qubits=6, n_layers=2
  d_model=128, d_state=16
  epochs=100, batch_size=32
  lr=0.001, weight_decay=0.0001
  early_stopping=20
================================================================================

Loading Data...
Loading Selective Copy dataset from data/synthetic_benchmarks/selective_copy/selective_copy_L1000_M8_seed2024.pt...
Dataset loaded successfully.
  - Task: selective_copy
  - Sequence length: 1000
  - Num channels: 2
  - Num markers: 8
  - Output length: 8
  - Total samples: 5000
  - Marker density: 0.8%
  - Baseline MSE: 0.0831
  - Input shape for model: torch.Size([5000, 2, 1000])
  - Target shape: torch.Size([5000, 8])
  - Training set: 4000
  - Validation set: 500
  - Test set: 500
Data loaded!
  Input: (2 channels, 1000 timesteps)
  Output dim: 8

Creating model...
Creating model: QuantumMambaSSM (ID: 1b)
  Group 1: quantum features → classical mixing (mamba)
Model parameters: 422,633
Verifying device placement...
  WARNING: feature_proj.0.weight is on cuda:0, moving to cuda
  WARNING: feature_proj.0.bias is on cuda:0, moving to cuda
  WARNING: feature_proj.1.weight is on cuda:0, moving to cuda
  WARNING: feature_proj.1.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.chunk_attention.0.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.chunk_attention.0.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.chunk_attention.2.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.chunk_attention.2.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.alpha_real is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.alpha_imag is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.beta_real is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.beta_imag is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.gamma_real is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.gamma_imag is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj1.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj1.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj2.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj2.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj3.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.proj3.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.input_proj.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.quantum_branches.input_proj.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.output_proj.0.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.output_proj.0.bias is on cuda:0, moving to cuda
  WARNING: quantum_processor.output_proj.1.weight is on cuda:0, moving to cuda
  WARNING: quantum_processor.output_proj.1.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.in_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.conv1d.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.conv1d.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.A_log is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.D is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.x_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.dt_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.dt_proj.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.ssm.out_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.out_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.norm.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.0.norm.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.in_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.conv1d.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.conv1d.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.A_log is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.D is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.x_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.dt_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.dt_proj.bias is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.ssm.out_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.out_proj.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.norm.weight is on cuda:0, moving to cuda
  WARNING: mamba_layers.1.norm.bias is on cuda:0, moving to cuda
  WARNING: output_norm.weight is on cuda:0, moving to cuda
  WARNING: output_norm.bias is on cuda:0, moving to cuda
  WARNING: output_layer.0.weight is on cuda:0, moving to cuda
  WARNING: output_layer.0.bias is on cuda:0, moving to cuda
  WARNING: output_layer.3.weight is on cuda:0, moving to cuda
  WARNING: output_layer.3.bias is on cuda:0, moving to cuda
Model moved to cuda

================================================================================
Training Started (epochs 1 to 100)
================================================================================

Epoch   1/100 (46.7s) * | Train MSE: 0.093265 | Val MSE: 0.087106
Epoch   2/100 (45.5s) * | Train MSE: 0.087309 | Val MSE: 0.083145
Epoch   3/100 (44.3s) * | Train MSE: 0.086098 | Val MSE: 0.082248
Epoch   5/100 (43.9s) * | Train MSE: 0.081231 | Val MSE: 0.073397
Epoch   6/100 (43.8s) * | Train MSE: 0.069669 | Val MSE: 0.056345
Epoch   7/100 (43.9s) * | Train MSE: 0.052757 | Val MSE: 0.043934
Epoch   8/100 (43.8s) * | Train MSE: 0.046611 | Val MSE: 0.041437
Epoch   9/100 (43.7s) * | Train MSE: 0.042064 | Val MSE: 0.038015
Epoch  10/100 (43.6s) * | Train MSE: 0.039704 | Val MSE: 0.035216
Epoch  12/100 (43.5s) * | Train MSE: 0.036693 | Val MSE: 0.033635
Epoch  13/100 (43.3s) * | Train MSE: 0.034403 | Val MSE: 0.026125
Epoch  14/100 (43.2s) * | Train MSE: 0.027685 | Val MSE: 0.022774
Epoch  15/100 (43.3s) | Train MSE: 0.026011 | Val MSE: 0.027972
Epoch  17/100 (43.4s) * | Train MSE: 0.022577 | Val MSE: 0.017412
Epoch  18/100 (43.5s) * | Train MSE: 0.020539 | Val MSE: 0.016395
Epoch  19/100 (43.4s) * | Train MSE: 0.018568 | Val MSE: 0.014496
Epoch  20/100 (43.3s) * | Train MSE: 0.016511 | Val MSE: 0.013191
Epoch  22/100 (45.0s) * | Train MSE: 0.015598 | Val MSE: 0.012986
Epoch  23/100 (44.8s) * | Train MSE: 0.014619 | Val MSE: 0.012928
Epoch  25/100 (44.9s) | Train MSE: 0.013465 | Val MSE: 0.013151
Epoch  30/100 (45.0s) * | Train MSE: 0.012024 | Val MSE: 0.012683
Epoch  35/100 (43.1s) | Train MSE: 0.010782 | Val MSE: 0.012902
Epoch  40/100 (43.0s) | Train MSE: 0.009226 | Val MSE: 0.013364
Epoch  45/100 (42.8s) | Train MSE: 0.007712 | Val MSE: 0.014232
Epoch  50/100 (42.9s) | Train MSE: 0.006616 | Val MSE: 0.014855

Early stopping at epoch 50 (no improvement for 20 epochs)

================================================================================
Training Complete!
================================================================================
Total Time: 2186.29s (36.44 min)
Best Val MSE: 0.012683
Test Results:
  MSE: 0.011938
  MAE: 0.071066
  R²: 0.8576
  Baseline MSE: 0.0830
  Improvement over baseline: 85.6%
Job completed: syn_1b_selective_copy_L1000_s2024
End time: Sun 04 Jan 2026 02:51:02 PM PST
