Starting job: syn_2a_selective_copy_L200_s2024
Date: Wed 07 Jan 2026 12:34:45 AM PST
Host: nid008288
GPU: NVIDIA A100-SXM4-80GB
Using GPU: NVIDIA A100-SXM4-80GB
================================================================================
SYNTHETIC BENCHMARK - SELECTIVE_COPY
================================================================================
Model ID: 2a (ClassicalQuantumAttention)
  Group 2: classical feat → quantum mix (transformer)
Task: selective_copy (regression)
Sequence Length: 200
Seed: 2024
Device: cuda
--------------------------------------------------------------------------------
Hyperparameters:
  n_qubits=6, n_layers=2
  d_model=128, d_state=16
  epochs=100, batch_size=32
  lr=0.001, weight_decay=0.0001
  early_stopping=20
================================================================================

Loading Data...
Loading Selective Copy dataset from data/synthetic_benchmarks/selective_copy/selective_copy_L200_M8_seed2024.pt...
Dataset loaded successfully.
  - Task: selective_copy
  - Sequence length: 200
  - Num channels: 2
  - Num markers: 8
  - Output length: 8
  - Total samples: 5000
  - Marker density: 4.0%
  - Baseline MSE: 0.0837
  - Input shape for model: torch.Size([5000, 2, 200])
  - Target shape: torch.Size([5000, 8])
  - Training set: 4000
  - Validation set: 500
  - Test set: 500
Data loaded!
  Input: (2 channels, 200 timesteps)
  Output dim: 8

Creating model...
Creating model: ClassicalQuantumAttention (ID: 2a)
  Group 2: classical features → quantum mixing (transformer)
Model parameters: 36,720
Verifying device placement...
  WARNING: feature_extractor.embedding.weight is on cuda:0, moving to cuda
  WARNING: feature_extractor.embedding.bias is on cuda:0, moving to cuda
  WARNING: chunk_attention.0.weight is on cuda:0, moving to cuda
  WARNING: chunk_attention.0.bias is on cuda:0, moving to cuda
  WARNING: chunk_attention.2.weight is on cuda:0, moving to cuda
  WARNING: chunk_attention.2.bias is on cuda:0, moving to cuda
  WARNING: quantum_attention.mix_coeffs is on cuda:0, moving to cuda
  WARNING: quantum_attention.qff_params is on cuda:0, moving to cuda
  WARNING: quantum_attention.param_proj.weight is on cuda:0, moving to cuda
  WARNING: quantum_attention.param_proj.bias is on cuda:0, moving to cuda
  WARNING: quantum_attention.output_proj.weight is on cuda:0, moving to cuda
  WARNING: quantum_attention.output_proj.bias is on cuda:0, moving to cuda
  WARNING: output_norm.weight is on cuda:0, moving to cuda
  WARNING: output_norm.bias is on cuda:0, moving to cuda
  WARNING: classifier.0.weight is on cuda:0, moving to cuda
  WARNING: classifier.0.bias is on cuda:0, moving to cuda
  WARNING: classifier.3.weight is on cuda:0, moving to cuda
  WARNING: classifier.3.bias is on cuda:0, moving to cuda
Model moved to cuda

================================================================================
Training Started (epochs 1 to 100)
================================================================================

Epoch   1/100 (205.2s) * | Train MSE: 0.098602 | Val MSE: 0.084100
Epoch   5/100 (197.9s) | Train MSE: 0.085702 | Val MSE: 0.085154
Epoch   7/100 (197.3s) * | Train MSE: 0.083284 | Val MSE: 0.078830
Epoch   8/100 (197.5s) * | Train MSE: 0.078427 | Val MSE: 0.076673
Epoch   9/100 (197.4s) * | Train MSE: 0.077445 | Val MSE: 0.076257
Epoch  10/100 (193.5s) | Train MSE: 0.077385 | Val MSE: 0.076566
Epoch  11/100 (193.9s) * | Train MSE: 0.076772 | Val MSE: 0.075676
Epoch  13/100 (193.5s) * | Train MSE: 0.076061 | Val MSE: 0.074945
Epoch  15/100 (193.3s) | Train MSE: 0.075208 | Val MSE: 0.075554
Epoch  16/100 (193.7s) * | Train MSE: 0.073937 | Val MSE: 0.072516
Epoch  18/100 (193.8s) * | Train MSE: 0.073297 | Val MSE: 0.071851
Epoch  19/100 (193.3s) * | Train MSE: 0.072878 | Val MSE: 0.071510
Epoch  20/100 (194.5s) | Train MSE: 0.072880 | Val MSE: 0.072091
Epoch  24/100 (193.4s) * | Train MSE: 0.072216 | Val MSE: 0.071328
Epoch  25/100 (193.2s) | Train MSE: 0.072013 | Val MSE: 0.071964
Epoch  27/100 (193.5s) * | Train MSE: 0.072045 | Val MSE: 0.070948
Epoch  28/100 (193.8s) * | Train MSE: 0.071798 | Val MSE: 0.070893
Epoch  30/100 (193.8s) * | Train MSE: 0.071665 | Val MSE: 0.070520
Epoch  34/100 (194.0s) * | Train MSE: 0.071259 | Val MSE: 0.070215
Epoch  35/100 (193.5s) * | Train MSE: 0.070732 | Val MSE: 0.070187
Epoch  36/100 (193.4s) * | Train MSE: 0.070519 | Val MSE: 0.069855
Epoch  37/100 (193.5s) * | Train MSE: 0.070265 | Val MSE: 0.069463
Epoch  39/100 (193.3s) * | Train MSE: 0.069374 | Val MSE: 0.067985
Epoch  40/100 (193.6s) * | Train MSE: 0.068275 | Val MSE: 0.067250
Epoch  42/100 (195.0s) * | Train MSE: 0.067126 | Val MSE: 0.066656
Epoch  43/100 (194.1s) * | Train MSE: 0.066954 | Val MSE: 0.066268
Epoch  44/100 (194.1s) * | Train MSE: 0.066540 | Val MSE: 0.065932
Epoch  45/100 (194.1s) * | Train MSE: 0.066420 | Val MSE: 0.065867
Epoch  46/100 (194.2s) * | Train MSE: 0.066283 | Val MSE: 0.065788
Epoch  48/100 (194.4s) * | Train MSE: 0.066206 | Val MSE: 0.065757
Epoch  50/100 (194.1s) | Train MSE: 0.066091 | Val MSE: 0.065976
Epoch  51/100 (194.6s) * | Train MSE: 0.066040 | Val MSE: 0.065657
Epoch  53/100 (194.3s) * | Train MSE: 0.065942 | Val MSE: 0.065573
Epoch  55/100 (194.5s) * | Train MSE: 0.065842 | Val MSE: 0.065502
Epoch  56/100 (194.4s) * | Train MSE: 0.065704 | Val MSE: 0.065474
Epoch  58/100 (207.8s) * | Train MSE: 0.065677 | Val MSE: 0.065311
Epoch  60/100 (211.3s) | Train MSE: 0.065595 | Val MSE: 0.065330
Epoch  65/100 (210.7s) * | Train MSE: 0.065401 | Val MSE: 0.065111
Epoch  69/100 (204.8s) * | Train MSE: 0.065157 | Val MSE: 0.064901
Epoch  70/100 (203.7s) | Train MSE: 0.065150 | Val MSE: 0.065123
Epoch  73/100 (208.3s) * | Train MSE: 0.064980 | Val MSE: 0.064779
Epoch  75/100 (205.6s) | Train MSE: 0.064978 | Val MSE: 0.064902
Epoch  77/100 (207.0s) * | Train MSE: 0.064910 | Val MSE: 0.064689
Epoch  78/100 (214.9s) * | Train MSE: 0.064894 | Val MSE: 0.064683
Epoch  79/100 (213.7s) * | Train MSE: 0.064833 | Val MSE: 0.064629
Epoch  80/100 (213.6s) | Train MSE: 0.064836 | Val MSE: 0.064763
Epoch  82/100 (211.1s) * | Train MSE: 0.064765 | Val MSE: 0.064548
Epoch  84/100 (212.6s) * | Train MSE: 0.064771 | Val MSE: 0.064492
Epoch  85/100 (211.7s) | Train MSE: 0.064741 | Val MSE: 0.064639
Epoch  90/100 (212.5s) | Train MSE: 0.064586 | Val MSE: 0.064495
Epoch  91/100 (213.2s) * | Train MSE: 0.064635 | Val MSE: 0.064467
Epoch  95/100 (213.0s) * | Train MSE: 0.064596 | Val MSE: 0.064464
Epoch  97/100 (207.1s) * | Train MSE: 0.064615 | Val MSE: 0.064461
Epoch  98/100 (211.2s) * | Train MSE: 0.064690 | Val MSE: 0.064460
Epoch  99/100 (216.2s) * | Train MSE: 0.064498 | Val MSE: 0.064459
Epoch 100/100 (215.8s) * | Train MSE: 0.064571 | Val MSE: 0.064458

================================================================================
Training Complete!
================================================================================
Total Time: 20159.72s (336.00 min)
Best Val MSE: 0.064458
Test Results:
  MSE: 0.064506
  MAE: 0.211026
  R²: 0.2316
  Baseline MSE: 0.0830
  Improvement over baseline: 22.3%

Results saved to: results/synthetic_benchmarks/synthetic_2a_selective_copy_L200_seed2024_results.json
Model saved to: results/synthetic_benchmarks/synthetic_2a_selective_copy_L200_seed2024_model.pt
Cleaned up training checkpoint: results/synthetic_benchmarks/checkpoints/checkpoint_2a_selective_copy_L200_seed2024.pt

================================================================================
SYNTHETIC BENCHMARK RUN COMPLETE
================================================================================
Model: 2a (ClassicalQuantumAttention)
Task: selective_copy
Seq Length: 200
Test MSE: 0.064506
Test R²: 0.2316
================================================================================

Job completed: syn_2a_selective_copy_L200_s2024
End time: Wed 07 Jan 2026 06:11:16 AM PST
